Lecture Outline: Medical action is permanent decsion making under uncertainty within limited time (“5 -Minutes”). The problem of the most successful AI/ML methods (e.g. deep learning; see the differences between AI-ML-DL here) is that they are often considered to be “black-boxes” which is not quite true. However, even if we understand the underlying mathematical and theoretical principles, it is difficult to re-enact and to answer the question of why a certain machine decision has been reached. A general serious drawback is that such models have no explicit declarative knowledge representation, hence have difficulty in generating the required explanatory structures – the context – which considerably limits the achievement of their full potential. Interestingly the “old symbolic and logic based AI-approaches” did have such explanatory structures, at least for a very narrow domain space. One future goal is in implicit knowledge elicitation through efficient human-AI interfaces.

Lecture Keywords: clinical decsion making, transparency, re-traceability, re-enaction, re-producibility, explainability

1. Topic 01 Decison Support Systems (DSS): Can Computers help making better decisions?
2. Topic 02 History of DSS = History of AI – explainable AI is actually the oldest field of Artificial Intelligence
3. Topic 03 Medical Informatics Example: Towards P4 Medicine
4. Topic 04 Medical Informatics Example: Case Based Reasoing (CBR)
Topic 05 Causal Reasoning
Topic 06 Explainability – Causality – Causability [1]
Topic 07 (Some) Methods of Explainable AI

Learning Goals: At the end of this lecture the students …
+ know the roots of decision making and early concepts of medical decision support systems (Advice Taker, MYCIN, GAMUTS)
+ see some examples of the problematic of medical decision making
+ have a first overview on the principles of explainable AI-methods
+ know some of the most relevant methods of explainable AI
